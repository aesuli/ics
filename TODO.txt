TODO
- target constraint-agnostic merge
- return message/error in jobs
- user management
    * ownership of datasets
    * ownership of classifiers
    * access list for datasets
    * access list for classifiers
    * tracking of who assigned labels
    * majority vote on multiple labels
    * user agreement
- table views
    * different sort criteria
- automatic DB creation
- use ids rather than names in batch jobs
- cleaning
    * purge unreferenced documents
    * periodically clean download directory
- other tools:
    * terminology extraction
- versioning
- backup of deleted data
- richer classifier info
    * estimated accuracy

TOMONITOR
- check for code injection

DONE
- minibatch learning
- delete not running jobs
- delete error jobs
- delete all jobs
- twitter integration
- add public flag to classifiers
- rename demo to public
- next document should always use filter
- add incomplete labeling browsing option
- fix training example error when doing data import (duplicate values)
- multi-label and single-label is only an option of data input and output
- create no label or one label classifiers
- add/remove single label
- true binary classifiers
- lightweight random indexing
- duplicate and combine functions are now implemented in the merge function
- single label classifier with yes-no labels in combine can be merged by label name or by classifier name
- table views
    * dataset table view
    * training table view
    * deletion of training examples
    * labeling from table views
- templates (mako)
- removed internal copies of js and css use CDN when possible
- move to w3css
- remove jquery-ui
- multilabel visualization in demo page
- multilabel visualization in type and code page
- fix missing label count of multilabel
- multilabel relevance sampling
- multilabel incertainty sampling
- add 'M' and 'S' to dropdown menu
- extend duplicate to multilabel
- extend extract to multilabel
- extend combine to multilabel
- multilabel data download
- multilabel classifiers
- text search in browse and code
    * extend to all browsing modes
- update demo labeling interface following the browse and label one
- dataset documents as table view
- classified dataset documents as table view
- fix classification jobs
- option to disable classifier's automatic labeling in UI
- changed the labeling process in UI:
    * optional visualization of suggestions
    * removed "skip"
    * changed "hide" to "non-relevant"
- bulk copy of training set on DB
- bulk insert of training set into DB
- bulk insert of dataset into DB
- description of classifier
- demo API page
- cost of batch classification
- paginated view for
    * dataset
    * users
    * classifiers
    * keys
    * ips
    * jobs
    * locks
    * classifications
- single limits and rates object
- datasets page using a table
- classifiers page using a table
- classifications page using a table
- users with limits
- users page using a table
- key admin page
- dedicated admin interface
- key-based access
    * rate-limited
    * amount-limited
- ip-based rate-limited access
- active browsing for multiclass classifiers
- remove garbage label from counts and listing of examples
- garbage label
- active auto browsing
- upload/download of binary classification models
- split actual job processor from job managing web service interface
- python client
- decouple app and services
- user admin page
- user authentication
    * add user db
    * add args.auth_path
- bug in renaming labels
- rename label
- rename dataset
- rename classifier
- extract binary classifiers from another classifier
- sorting of datasets and classifiers
- compose classifiers into a multilabel classifier
- bug in picking of models: move partial into get_TEXT_analyzer (resolved after package update?)
- file import
    * skip comment lines, i.e., those starting with #
    * no header example import (two passes)
    * automatic encoding management
- bug in autoadvance on skip
- locks on db
- duplicate classifiers
- lock classifiers on update
- logging
- batch/background processing
    * job completion waiting
    * put jobs queue (BackgroundProcessor._queue) on db
    * upload
    * training with uploaded examples
    * jobs update
    * classification
- "browse and label" page
- "classifiers" page
    * simple list, info and deletion
- confirm on delete
- create classifiers from labeled examples
- file import
    * unlabeled collection upload
    * labeled collection upload
- file export
    * examples for a classifier
    * dataset download
    * classification jobs page
    * dataset download with classification
- ajax jobs, not template
- document datasets
    * definition in db
    * creation
    * deletion
    * classification
- optimize db use
    * return feedback classifications for human-labeled docs
    * remove text duplication
    * use ids not string for classifiers and classes
- templates (mako)
    * version
    * header
    * footer
    * user info
    * packages and licences
- "all correct" button
- use classify, instead of score
- fix arrays [] passed to cherrypy
- db abstraction
- examples db
- serious db engine (mongodb-NO, sqlite-NO, sqlalchemy+postgres)
- fix missing cascade on labels (switched to postgres)
- richer classifier info
    * last update
    * number of examples observed
