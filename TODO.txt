TODO
- file import
    * labeled collection upload
- classification jobs page
- create classifiers from labeled examples
- document datasets
    * classification
- file export
    * collection download with classification
- twitter integration
- switch to angular.js
- memory problems:
    * 64 bit fixes it?
    * queue of update/classification requests to save memory?
- classification management
- batch processing
- richer classifier info
    * number of examples observed
    * estimated accuracy
- templates (mako)
    * footer
    * user info
    * version
- user authentication
- store source of classification (which user?)
- user authorization

DONE
- file import
    * unlabeled collection upload
- document datasets
    * definition in db
    * creation
    * deletion
- optimize db use
    * return feedback classifications for human-labeled docs
    * remove text duplication
    * use ids not string for classifiers and classes
- templates (mako)
    * header
- "all correct" button
- use classify, instead of score
- fix arrays [] passed to cherrypy
- db abstraction
- examples db
- serious db engine (mongodb-NO, sqlite-NO, sqlalchemy+postgres)
- fix missing cascade on labels (switched to postgres)
- richer classifier info
    * last update
