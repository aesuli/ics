TODO
- multilabel visualization in demo page
- multilabel visualization in type and code page
- labeling from table views
- automatic DB creation
- use ids rather than names in batch jobs
- user authorization profiles
- cleaning
    * purge unreferenced documents
    * periodically clean download directory
- check for sql/js/etc code injection
- other tools:
    * terminology extraction
- versioning
- backup of deleted data
- twitter integration
- richer classifier info
    * estimated accuracy
- templates (mako)
- store source of classification (which user?)

TOMONITOR
- strip input strings

DONE
- fix missing label count of multilabel
- multilabel relevance sampling
- multilabel incertainty sampling
- add 'M' and 'S' to dropdown menu
- extend duplicate to multilabel
- extend extract to multilabel
- extend combine to multilabel
- multilabel data download
- multilabel classifiers
- text search in browse and code
    * extend to all browsing modes
- update demo labeling interface following the browse and label one
- dataset documents as table view
- classified dataset documents as table view
- fix classification jobs
- option to disable classifier's automatic labeling in UI
- changed the labeling process in UI:
    * optional visualization of suggestions
    * removed "skip"
    * changed "hide" to "non-relevant"
- bulk copy of training set on DB
- bulk insert of training set into DB
- bulk insert of dataset into DB
- description of classifier
- demo API page
- cost of batch classification
- paginated view for
    * dataset
    * users
    * classifiers
    * keys
    * ips
    * jobs
    * locks
    * classifications
- single limits and rates object
- datasets page using a table
- classifiers page using a table
- classifications page using a table
- users with limits
- users page using a table
- key admin page
- dedicated admin interface
- key-based access
    * rate-limited
    * amount-limited
- ip-based rate-limited access
- active browsing for multiclass classifiers
- remove garbage label from counts and listing of examples
- garbage label
- active auto browsing
- upload/download of binary classification models
- split actual job processor from job managing web service interface
- python client
- decouple app and services
- user admin page
- user authentication
    * add user db
    * add args.auth_path
- bug in renaming labels
- rename label
- rename dataset
- rename classifier
- extract binary classifiers from another classifier
- sorting of datasets and classifiers
- compose classifiers into a multilabel classifier
- bug in picking of models: move partial into get_TEXT_analyzer (resolved after package update?)
- file import
    * skip comment lines, i.e., those starting with #
    * no header example import (two passes)
    * automatic encoding management
- bug in autoadvance on skip
- locks on db
- duplicate classifiers
- lock classifiers on update
- logging
- batch/background processing
    * job completion waiting
    * put jobs queue (BackgroundProcessor._queue) on db
    * upload
    * training with uploaded examples
    * jobs update
    * classification
- "browse and label" page
- "classifiers" page
    * simple list, info and deletion
- confirm on delete
- create classifiers from labeled examples
- file import
    * unlabeled collection upload
    * labeled collection upload
- file export
    * examples for a classifier
    * dataset download
    * classification jobs page
    * dataset download with classification
- ajax jobs, not template
- document datasets
    * definition in db
    * creation
    * deletion
    * classification
- optimize db use
    * return feedback classifications for human-labeled docs
    * remove text duplication
    * use ids not string for classifiers and classes
- templates (mako)
    * version
    * header
    * footer
    * user info
    * packages and licences
- "all correct" button
- use classify, instead of score
- fix arrays [] passed to cherrypy
- db abstraction
- examples db
- serious db engine (mongodb-NO, sqlite-NO, sqlalchemy+postgres)
- fix missing cascade on labels (switched to postgres)
- richer classifier info
    * last update
    * number of examples observed
